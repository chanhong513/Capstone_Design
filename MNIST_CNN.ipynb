{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_74180\\1879146444.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.290342\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.288253\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.293523\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.303753\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.282339\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.253622\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.264005\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.237305\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.286587\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.282927\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.226380\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.228175\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.160106\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.159914\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.052126\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.994421\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.746433\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.753162\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.415732\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.285214\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.060901\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.043775\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.907852\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.759865\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.789662\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.682057\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.582748\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.574998\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.645495\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.644129\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.548762\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.664588\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.605921\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.622613\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.719829\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.589811\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.375002\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.435977\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.591119\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.596352\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.675933\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.581389\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.497453\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.603948\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.333704\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.847526\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.642798\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.482024\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.347787\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.566014\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.470735\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.224504\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.437691\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.349612\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.441140\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.468765\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.434919\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.679717\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.447530\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.516537\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.291097\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.484533\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.357984\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.621785\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.369961\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.336298\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.400320\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.401913\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.467457\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.530510\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.583171\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.278118\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.703474\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.606042\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.611244\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.579886\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.371977\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.759624\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.656452\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.428157\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.225876\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.431817\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.305036\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.393713\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.441768\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.424564\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.379082\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.417421\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.533861\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.456160\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.340765\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.705858\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.468749\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.310855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_74180\\1879146444.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3875, Accuracy: 8860/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.262854\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.306302\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.309740\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.417463\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.160288\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.250967\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.318191\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.584084\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.368598\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.382919\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.445712\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.283825\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.380465\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.524636\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.351120\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.471046\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.370606\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.359901\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.586549\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.273781\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.685122\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.597071\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.291153\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.418172\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.456371\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.539669\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.453313\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.521350\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.419831\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.346952\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.248778\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.351935\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.298793\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.321833\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.498901\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.502140\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.719779\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.394058\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.380669\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.488971\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.513899\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.201269\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.632529\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.414970\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.199016\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.315171\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.311689\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.322627\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.382508\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.440925\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.294927\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.261934\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.326758\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.432645\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.386610\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.454702\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.264512\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.455208\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.299620\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.442166\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.325405\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.542155\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.244179\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.132158\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.276199\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.349965\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.295864\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.251676\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.454455\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.233164\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.404506\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.437560\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.490259\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.386450\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.337912\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.330152\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.168289\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.335438\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.252001\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.224597\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.535178\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.171168\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.495150\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.204719\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.373055\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.361892\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.327127\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.393683\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.121832\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.377387\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.443432\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.254959\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.413869\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.184197\n",
      "\n",
      "Test set: Average loss: 0.3300, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.234276\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.296874\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.387108\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.336348\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.336995\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.388249\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.419053\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.352546\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.171626\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.218679\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.302025\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.230265\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.436694\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.483019\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.363593\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.300015\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.349156\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.351176\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.319263\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.258477\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.316036\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.379420\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.212023\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.539784\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.265011\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.327664\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.421465\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.480307\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.208894\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.297791\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.266146\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.321679\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.324933\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.291096\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.445417\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.290383\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.464909\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.262131\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.328308\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.320491\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.874179\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.414843\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.316457\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.162615\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.340482\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.514317\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.295686\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.360111\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.235402\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.469001\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.323889\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.378809\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.246277\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.302137\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.474322\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.503801\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.590012\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.653719\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.300617\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.274470\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.568735\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.323483\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.379144\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.271016\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.344435\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.355820\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.537325\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.273674\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.142825\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.188913\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.197956\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.221224\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.297459\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.161291\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.303420\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.317279\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.396440\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.196956\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.353610\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.408523\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.338540\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.240912\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.418447\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.151600\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.333446\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.315439\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.266092\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.309814\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.161241\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.242305\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.186555\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.336538\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.388156\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.084958\n",
      "\n",
      "Test set: Average loss: 0.2938, Accuracy: 9160/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.235081\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.382679\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.575301\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.377805\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.472391\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.189907\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.516792\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.201706\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.257249\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.424106\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.297802\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.361083\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.301512\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.346739\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.456567\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.122192\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.353374\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.234264\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.293747\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.290480\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.305126\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.439956\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.196712\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.335416\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.287188\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.445279\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.187611\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.241453\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.488877\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.370364\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.385641\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.170275\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.379025\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.265374\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.395740\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.341801\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.174869\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.240463\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.423151\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.351161\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.174657\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.322945\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.284623\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.456355\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.278226\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.226736\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.293464\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.203007\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.378329\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.188830\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.248628\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.356592\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.189846\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.236193\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.210549\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.341838\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.390133\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.159758\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.328363\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.254647\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.288092\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.307296\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.291950\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.189105\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.193130\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.205205\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.233727\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.248269\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.522305\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.302906\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.280276\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.196552\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.256389\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.433497\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.149050\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.179411\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.127209\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.106166\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.379827\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.235586\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.308557\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.167269\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.436699\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.265261\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.258968\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.251152\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.348620\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.233363\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.446466\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.099630\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.224352\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.332484\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.373281\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.296386\n",
      "\n",
      "Test set: Average loss: 0.2721, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.228223\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.295586\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.343367\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.324019\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.203737\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.442395\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.229094\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.377957\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.184124\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.242375\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.208612\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.633220\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.177438\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.317987\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.089809\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.139696\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.284843\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.418181\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.348900\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.185450\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.253119\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.431190\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.301173\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.269174\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.168468\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.142507\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.343676\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.411874\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.394839\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.220262\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.365316\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.373127\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.359555\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.252090\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.231492\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.273683\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.307622\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.136109\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.162498\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.149832\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.538860\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.236756\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.251373\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.143827\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.175768\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.254355\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.217469\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.209918\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.597556\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.165002\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.283899\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.164378\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.263565\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.071739\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.262192\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.358839\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.190608\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.356315\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.270874\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.339334\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.198086\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.432907\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.378986\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.226889\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.354657\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.250606\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.194029\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.308676\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.113229\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.271948\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.265853\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.160906\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.155785\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.395165\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.260834\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.358688\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.311348\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.214161\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.347836\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.214938\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.141863\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.121967\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.376077\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.198613\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.236546\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.196069\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.195329\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.084654\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.446912\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.202992\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.082625\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.258502\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.345720\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.173265\n",
      "\n",
      "Test set: Average loss: 0.2433, Accuracy: 9298/10000 (93%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.261793\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.425981\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.180248\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.253030\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.236259\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.144557\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.127545\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.247500\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.253295\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.131112\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.289120\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.345520\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.316568\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.364925\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.229510\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.408850\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.396559\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.102250\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.541620\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.254144\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.197101\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.338726\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.214715\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.406307\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.196487\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.383746\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.187391\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.208343\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.211838\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.292125\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.269484\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.164013\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.322692\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.153069\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.227977\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.224349\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.203164\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.232436\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.272590\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.123967\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.166319\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.347596\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.354911\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.078299\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.218795\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.272193\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.381648\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.117351\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.232953\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.395541\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.363002\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.275013\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.204947\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.110183\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.521989\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.370812\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.314035\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.237131\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.181157\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.305921\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.302741\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.200917\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.160343\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.153527\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.345339\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.194196\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.312929\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.321243\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.271652\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.202337\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.321569\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.201967\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.165663\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.187973\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.235391\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.039366\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.133360\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.162765\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.416688\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.434658\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.215770\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.352588\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.163392\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.277359\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.318405\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.477623\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.329244\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.219138\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.200611\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.324507\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.444463\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.290598\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.276772\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.243755\n",
      "\n",
      "Test set: Average loss: 0.2329, Accuracy: 9322/10000 (93%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.254324\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.325544\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.363143\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.310182\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.352394\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.274090\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.129580\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.145013\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.167476\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.254836\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.250211\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.217554\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.225639\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.262393\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.197466\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.240197\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.318964\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.405856\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.241565\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.350401\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.191262\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.226283\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.305080\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.228680\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.364590\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.247200\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.273869\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.284062\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.221496\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.185943\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.127569\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.155821\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.387058\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.309158\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.275017\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.227446\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.159500\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.478027\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.204470\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.446607\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.205362\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.308085\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.142716\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.198645\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.223421\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.299771\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.240219\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.159861\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.133867\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.550213\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.194579\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.087984\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.340836\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.163940\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.189678\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.156296\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.231210\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.167471\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.434044\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.239733\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.134971\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.284499\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.148288\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.160247\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.289651\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.061685\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.303950\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.377496\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.426766\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.208594\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.279463\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.196909\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.194265\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.278942\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.419623\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.248853\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.136457\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.179009\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.150760\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.288683\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.257293\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.174034\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.129557\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.283319\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.217231\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.127101\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.108100\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.343646\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.123960\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.193412\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.248253\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.217803\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.166453\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.306315\n",
      "\n",
      "Test set: Average loss: 0.2269, Accuracy: 9338/10000 (93%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.328951\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.354598\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.337662\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.452628\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.266023\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.100527\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.102583\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.195248\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.181577\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.167513\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.115175\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.157338\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.233246\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.327255\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.360629\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.454524\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.204687\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.125940\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.305598\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.297809\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.212349\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.412878\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.543113\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.143036\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.294895\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.200280\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.177414\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.321120\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.350022\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.238451\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.318614\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.319240\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.184522\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.401538\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.218130\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.283097\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.159406\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.253703\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.137629\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.194007\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.211099\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.081932\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.346044\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.133754\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.133533\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.217732\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.202522\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.359782\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.226237\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.165143\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.051380\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.171398\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.271421\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.155138\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.301748\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.334076\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.132056\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.066784\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.213964\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.182321\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.386156\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.122762\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.210277\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.215351\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.078949\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.283390\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.287603\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.519243\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.248260\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.243436\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.233009\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.206074\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.228212\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.257063\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.143841\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.267227\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.311685\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.178527\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.192426\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.185091\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.200473\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.255340\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.326701\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.301974\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.322770\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.351669\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.198363\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.151431\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.278926\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.318331\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.160772\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.474301\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.292232\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.256359\n",
      "\n",
      "Test set: Average loss: 0.2046, Accuracy: 9388/10000 (94%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.184622\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.110500\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.194124\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.316865\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.148505\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.317590\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.231756\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.274124\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.140435\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.200971\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.090468\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.299268\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.503467\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.216434\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.150384\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.388786\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.374467\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.069322\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.301882\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.128449\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.175139\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.267772\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.318978\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.340182\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.148246\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.233367\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.196215\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.309718\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.183530\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.211756\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.170182\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.198282\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.355887\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.166101\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.197880\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.309729\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.597558\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.236275\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.235089\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.156316\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.455601\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.313024\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.409113\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.126152\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.438094\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.366564\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.088310\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.144655\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.105478\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.258575\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.281811\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.229224\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.398883\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.122969\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.198821\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.177468\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.444516\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.248055\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.272274\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.125150\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.449168\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.151031\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.194516\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.160608\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.311851\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.183483\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.200836\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.075851\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.208517\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.096802\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.187138\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.302040\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.486825\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.085084\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.162577\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.144889\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.178213\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.323315\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.504947\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.162485\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.195574\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.162340\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.222610\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.275950\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.282564\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.259206\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.160384\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.203235\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.272819\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.335821\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.160368\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.219341\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.280728\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.253252\n",
      "\n",
      "Test set: Average loss: 0.2005, Accuracy: 9394/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "\n",
    "\n",
    "class IEEC(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super(IEEC, self).__init__()\n",
    "        \n",
    "        self.conv1_out_np = np.zeros((1, 3, 24, 24))\n",
    "        self.avp1_out_np = np.zeros((1, 3, 12, 12))\n",
    "        self.conv2_out_np = np.zeros((1, 3, 8, 8))\n",
    "        self.avp2_out_np = np.zeros((1, 3, 4, 4))\n",
    "        self.fc_in_np = np.zeros((1, 48))\n",
    "        self.fc_out_np = np.zeros((1, 10))\n",
    "        \n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5, bias = False) \n",
    "        self.conv2 = nn.Conv2d(3, 3, kernel_size=5, bias = False)\n",
    "        self.mp = nn.AvgPool2d(2)\n",
    "        self.fc_1 = nn.Linear(48, 10, bias = False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        self.conv1_out_np = x.detach().numpy()\n",
    "        x = F.relu(self.mp(x))\n",
    "        self.avp1_out_np = x.detach().numpy()\n",
    "        x = self.conv2(x)\n",
    "        self.conv2_out_np = x.detach().numpy()\n",
    "        x = F.relu(self.mp(x))\n",
    "        self.avp2_out_np = x.detach().numpy()\n",
    "        x = x.view(in_size, -1)\n",
    "        self.fc_in_np = x.detach().numpy()\n",
    "        x = self.fc_1(x)\n",
    "        self.fc_out_np = x.detach().numpy()\n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "   \n",
    "model = IEEC()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "          \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed\n",
      "tensor([[ 81,  80,  71,  64,  98],\n",
      "        [ 36,  58,  32,  64,  81],\n",
      "        [-21, -35, -18, -16,   2],\n",
      "        [-83, -55, -58, -62, -30],\n",
      "        [-53, -55, -50, -27, -22]], dtype=torch.int32)\n",
      "tensor([[ 45,  43,  38,  42,  35],\n",
      "        [ -6,   5,   8,  13,   2],\n",
      "        [-26, -37,  -2, -30,   0],\n",
      "        [-34, -36, -22,   6,  -3],\n",
      "        [-17,  15,  -2,  -8,  -2]], dtype=torch.int32)\n",
      "tensor([[ -6, -27, -12, -16, -31],\n",
      "        [ 20,  38,  40,  43,  33],\n",
      "        [ 34,  66,  50,  77,  61],\n",
      "        [ 67,  84,  92,  65,  57],\n",
      "        [ 61,  79,  72,  46,  42]], dtype=torch.int32)\n",
      "Unsigned\n",
      "tensor([[ 81,  80,  71,  64,  98],\n",
      "        [ 36,  58,  32,  64,  81],\n",
      "        [235, 221, 238, 240,   2],\n",
      "        [173, 201, 198, 194, 226],\n",
      "        [203, 201, 206, 229, 234]], dtype=torch.int32)\n",
      "tensor([[ 45,  43,  38,  42,  35],\n",
      "        [250,   5,   8,  13,   2],\n",
      "        [230, 219, 254, 226,   0],\n",
      "        [222, 220, 234,   6, 253],\n",
      "        [239,  15, 254, 248, 254]], dtype=torch.int32)\n",
      "tensor([[250, 229, 244, 240, 225],\n",
      "        [ 20,  38,  40,  43,  33],\n",
      "        [ 34,  66,  50,  77,  61],\n",
      "        [ 67,  84,  92,  65,  57],\n",
      "        [ 61,  79,  72,  46,  42]], dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\4045124262.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv1_weight_1 =  torch.tensor((model.conv1.weight.data[0][0]*128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\4045124262.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv1_weight_2 =  torch.tensor((model.conv1.weight.data[1][0]*128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\4045124262.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv1_weight_3 =  torch.tensor((model.conv1.weight.data[2][0]*128), dtype = torch.int32)\n"
     ]
    }
   ],
   "source": [
    "int_conv1_weight_1 =  torch.tensor((model.conv1.weight.data[0][0]*128), dtype = torch.int32)\n",
    "int_conv1_weight_2 =  torch.tensor((model.conv1.weight.data[1][0]*128), dtype = torch.int32)\n",
    "int_conv1_weight_3 =  torch.tensor((model.conv1.weight.data[2][0]*128), dtype = torch.int32)\n",
    "\n",
    "print(\"Signed\")\n",
    "print(int_conv1_weight_1)\n",
    "print(int_conv1_weight_2)\n",
    "print(int_conv1_weight_3)\n",
    "\n",
    "# signed int => unsigned int\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv1_weight_1[i][j] < 0:\n",
    "            int_conv1_weight_1[i][j] += 256\n",
    "        if int_conv1_weight_2[i][j] < 0:\n",
    "            int_conv1_weight_2[i][j] += 256\n",
    "        if int_conv1_weight_3[i][j] < 0:\n",
    "            int_conv1_weight_3[i][j] += 256\n",
    "\n",
    "\n",
    "print (\"Unsigned\")\n",
    "print(int_conv1_weight_1)\n",
    "print(int_conv1_weight_2)\n",
    "print(int_conv1_weight_3)\n",
    "\n",
    "np.savetxt('conv1_weight_1.txt', int_conv1_weight_1, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv1_weight_2.txt', int_conv1_weight_2, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv1_weight_3.txt', int_conv1_weight_3, fmt='%1.2x',delimiter = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 5, 5])\n",
      "Signed\n",
      "tensor([[  8,  18,   6, -15, -38],\n",
      "        [ 13,  20,  37,  32,  22],\n",
      "        [ 52,  38,  65,  72,  40],\n",
      "        [ 53,  48,  67,  53,  15],\n",
      "        [ 25,  23,  10,  -9, -11]], dtype=torch.int32)\n",
      "tensor([[  0, -10,  13,  28, -16],\n",
      "        [ 19,   6,  10,  18,  19],\n",
      "        [ -9,  20,  20,  24,  25],\n",
      "        [ 10,   6,  14,  29,   9],\n",
      "        [  3,  -3,  17,   0,   0]], dtype=torch.int32)\n",
      "tensor([[ 29, -11, -11,  67,  29],\n",
      "        [ -5,  -6,   7,  70,  30],\n",
      "        [-25, -14, -15, -14,  14],\n",
      "        [ -9, -26, -60, -40, -24],\n",
      "        [ 43,  36,   4,  29,   6]], dtype=torch.int32) \n",
      "\n",
      "tensor([[ 13,   0,  14,   0,  -1],\n",
      "        [  5,   0, -22,  -6, -12],\n",
      "        [-23, -21, -42, -33, -13],\n",
      "        [-25, -49, -49, -22,  -1],\n",
      "        [-31, -34, -47, -27,  -7]], dtype=torch.int32)\n",
      "tensor([[ -1,   2,  -1,   3,  10],\n",
      "        [  8,   0, -11, -13,   1],\n",
      "        [  9,   0, -15,  -2,  11],\n",
      "        [ -3, -13, -27, -16, -18],\n",
      "        [-11, -16,   4,  -7,  -5]], dtype=torch.int32)\n",
      "tensor([[ -1,  -6, -26, -13,  19],\n",
      "        [  4,  -1,  16,  36,  49],\n",
      "        [ 27,   6,  55,  38, -24],\n",
      "        [  4,  33,  43, -10, -41],\n",
      "        [ 45,  50,  47,   5,  -8]], dtype=torch.int32) \n",
      "\n",
      "tensor([[-9,  0, 21, 34, 41],\n",
      "        [-2, -4,  0, 13, 41],\n",
      "        [ 1, 40, 55, 28, 21],\n",
      "        [30, 47, 46, 45, 36],\n",
      "        [23, 34, 39, 35, 28]], dtype=torch.int32)\n",
      "tensor([[ -9, -19,  -5,   5,  -3],\n",
      "        [  9,   8, -16, -11,  16],\n",
      "        [ -6,   0,  -6,   9,   0],\n",
      "        [  7,   8,  36,  26,  24],\n",
      "        [ 16,  25,  15,  32,  11]], dtype=torch.int32)\n",
      "tensor([[   0,  -58, -101,  -90,  -85],\n",
      "        [  21,  -32,  -30,  -45,  -58],\n",
      "        [  71,   38,   33,   26,    9],\n",
      "        [  58,   14,   14,   36,   38],\n",
      "        [  -1,    0,   -6,   16,   32]], dtype=torch.int32) \n",
      "\n",
      "Unsigned\n",
      "tensor([[  8,  18,   6, 241, 218],\n",
      "        [ 13,  20,  37,  32,  22],\n",
      "        [ 52,  38,  65,  72,  40],\n",
      "        [ 53,  48,  67,  53,  15],\n",
      "        [ 25,  23,  10, 247, 245]], dtype=torch.int32)\n",
      "tensor([[  0, 246,  13,  28, 240],\n",
      "        [ 19,   6,  10,  18,  19],\n",
      "        [247,  20,  20,  24,  25],\n",
      "        [ 10,   6,  14,  29,   9],\n",
      "        [  3, 253,  17,   0,   0]], dtype=torch.int32)\n",
      "tensor([[ 29, 245, 245,  67,  29],\n",
      "        [251, 250,   7,  70,  30],\n",
      "        [231, 242, 241, 242,  14],\n",
      "        [247, 230, 196, 216, 232],\n",
      "        [ 43,  36,   4,  29,   6]], dtype=torch.int32) \n",
      "\n",
      "tensor([[ 13,   0,  14,   0, 255],\n",
      "        [  5,   0, 234, 250, 244],\n",
      "        [233, 235, 214, 223, 243],\n",
      "        [231, 207, 207, 234, 255],\n",
      "        [225, 222, 209, 229, 249]], dtype=torch.int32)\n",
      "tensor([[255,   2, 255,   3,  10],\n",
      "        [  8,   0, 245, 243,   1],\n",
      "        [  9,   0, 241, 254,  11],\n",
      "        [253, 243, 229, 240, 238],\n",
      "        [245, 240,   4, 249, 251]], dtype=torch.int32)\n",
      "tensor([[255, 250, 230, 243,  19],\n",
      "        [  4, 255,  16,  36,  49],\n",
      "        [ 27,   6,  55,  38, 232],\n",
      "        [  4,  33,  43, 246, 215],\n",
      "        [ 45,  50,  47,   5, 248]], dtype=torch.int32) \n",
      "\n",
      "tensor([[247,   0,  21,  34,  41],\n",
      "        [254, 252,   0,  13,  41],\n",
      "        [  1,  40,  55,  28,  21],\n",
      "        [ 30,  47,  46,  45,  36],\n",
      "        [ 23,  34,  39,  35,  28]], dtype=torch.int32)\n",
      "tensor([[247, 237, 251,   5, 253],\n",
      "        [  9,   8, 240, 245,  16],\n",
      "        [250,   0, 250,   9,   0],\n",
      "        [  7,   8,  36,  26,  24],\n",
      "        [ 16,  25,  15,  32,  11]], dtype=torch.int32)\n",
      "tensor([[  0, 198, 155, 166, 171],\n",
      "        [ 21, 224, 226, 211, 198],\n",
      "        [ 71,  38,  33,  26,   9],\n",
      "        [ 58,  14,  14,  36,  38],\n",
      "        [255,   0, 250,  16,  32]], dtype=torch.int32) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_11 =  torch.tensor((model.conv2.weight.data[0][0]* 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_12 =  torch.tensor((model.conv2.weight.data[0][1]* 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_13 =  torch.tensor((model.conv2.weight.data[0][2]* 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_21 =  torch.tensor((model.conv2.weight.data[1][0] * 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_22 =  torch.tensor((model.conv2.weight.data[1][1] * 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_23 =  torch.tensor((model.conv2.weight.data[1][2] * 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_31 =  torch.tensor((model.conv2.weight.data[2][0] * 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_32 =  torch.tensor((model.conv2.weight.data[2][1] * 128), dtype = torch.int32)\n",
      "C:\\Users\\chanh\\AppData\\Local\\Temp\\ipykernel_15268\\469399959.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  int_conv2_weight_33 =  torch.tensor((model.conv2.weight.data[2][2] * 128), dtype = torch.int32)\n"
     ]
    }
   ],
   "source": [
    "############## Conv2 가중치 값 HEX 추출 ############\n",
    "\n",
    "print(np.shape(model.conv2.weight))\n",
    "\n",
    "# float => int\n",
    "int_conv2_weight_11 =  torch.tensor((model.conv2.weight.data[0][0]* 128), dtype = torch.int32)\n",
    "int_conv2_weight_12 =  torch.tensor((model.conv2.weight.data[0][1]* 128), dtype = torch.int32)\n",
    "int_conv2_weight_13 =  torch.tensor((model.conv2.weight.data[0][2]* 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_21 =  torch.tensor((model.conv2.weight.data[1][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_22 =  torch.tensor((model.conv2.weight.data[1][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_23 =  torch.tensor((model.conv2.weight.data[1][2] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_31 =  torch.tensor((model.conv2.weight.data[2][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_32 =  torch.tensor((model.conv2.weight.data[2][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_33 =  torch.tensor((model.conv2.weight.data[2][2] * 128), dtype = torch.int32)\n",
    "\n",
    "print (\"Signed\")\n",
    "print(int_conv2_weight_11)\n",
    "print(int_conv2_weight_12)\n",
    "print(int_conv2_weight_13, '\\n')\n",
    "\n",
    "print(int_conv2_weight_21)\n",
    "print(int_conv2_weight_22)\n",
    "print(int_conv2_weight_23, '\\n')\n",
    "\n",
    "print(int_conv2_weight_31)\n",
    "print(int_conv2_weight_32)\n",
    "print(int_conv2_weight_33, '\\n')\n",
    "\n",
    "# signed int => unsigned int\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv2_weight_11[i][j] < 0:\n",
    "            int_conv2_weight_11[i][j] += 256\n",
    "        if int_conv2_weight_12[i][j] < 0:\n",
    "            int_conv2_weight_12[i][j] += 256\n",
    "        if int_conv2_weight_13[i][j] < 0:\n",
    "            int_conv2_weight_13[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_21[i][j] < 0:\n",
    "            int_conv2_weight_21[i][j] += 256\n",
    "        if int_conv2_weight_22[i][j] < 0:\n",
    "            int_conv2_weight_22[i][j] += 256\n",
    "        if int_conv2_weight_23[i][j] < 0:\n",
    "            int_conv2_weight_23[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_31[i][j] < 0:\n",
    "            int_conv2_weight_31[i][j] += 256\n",
    "        if int_conv2_weight_32[i][j] < 0:\n",
    "            int_conv2_weight_32[i][j] += 256\n",
    "        if int_conv2_weight_33[i][j] < 0:\n",
    "            int_conv2_weight_33[i][j] += 256\n",
    "\n",
    "print (\"Unsigned\")\n",
    "print(int_conv2_weight_11)\n",
    "print(int_conv2_weight_12)\n",
    "print(int_conv2_weight_13, '\\n')\n",
    "\n",
    "print(int_conv2_weight_21)\n",
    "print(int_conv2_weight_22)\n",
    "print(int_conv2_weight_23, '\\n')\n",
    "\n",
    "print(int_conv2_weight_31)\n",
    "print(int_conv2_weight_32)\n",
    "print(int_conv2_weight_33, '\\n')\n",
    "\n",
    "np.savetxt('conv2_weight_11.txt', int_conv2_weight_11, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_12.txt', int_conv2_weight_12, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_13.txt', int_conv2_weight_13, fmt='%1.2x',delimiter = \" \")\n",
    "\n",
    "np.savetxt('conv2_weight_21.txt', int_conv2_weight_21, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_22.txt', int_conv2_weight_22, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_23.txt', int_conv2_weight_23, fmt='%1.2x',delimiter = \" \")\n",
    "\n",
    "np.savetxt('conv2_weight_31.txt', int_conv2_weight_31, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_32.txt', int_conv2_weight_32, fmt='%1.2x',delimiter = \" \")\n",
    "np.savetxt('conv2_weight_33.txt', int_conv2_weight_33, fmt='%1.2x',delimiter = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 48])\n",
      "tensor([[  1,  12,  27,   1,  -1,  -3,  -5, -10,  -3, -64, -26,  27,  30, -36,\n",
      "          24,  43,  12,   6,   2,  -8,  34,  34, -13,   5,  28,  11,  12,  -4,\n",
      "          -7,  -5,  13,   9,   8, -13,   6,  14, -11, -16, -30, -36, -40,  -8,\n",
      "         -25, -41,   9,  34,  16,  -9],\n",
      "        [-36,   0, -69,   4, -15,  28,  -3, -16, -56,  48, -39,   7, -31,  59,\n",
      "         -50,  10, -13, -23,  44, -16, -20,  -2,  10, -52, -26,  33, -21,  22,\n",
      "          45, -13, -24,   2, -38,   4, -21, -22,  45, -11, -13,  34,  15, -35,\n",
      "          -5,  27,  -5,  30,  24,  38],\n",
      "        [ 25,  38,  19, -44,  30, -13, -13, -33, -18, -40, -18,   0,   0, -13,\n",
      "          38,  37, -59, -12, -42,  -1,  13,  10,  -2,  27,  65,  31, -16, -29,\n",
      "          14,   9,   5,  19,  33,  10,  11,  -7,  47,  17,  -7,   7,  17, -10,\n",
      "           8,   4,  20, -18,  37,  74],\n",
      "        [ 30,  35,  21, -38,   2,   8,  -7,  21,  17,  26,   9, -16,  22,   2,\n",
      "          29,  22, -58, -48,   4,  16, -21, -12, -12, -24,  -3, -29,  -9,  14,\n",
      "           8,   0,  15,  26,  30,   3,  -7, -21,   4, -23, -10, -12,  41, -22,\n",
      "          -9, -19,  50,  -5,  12,   0],\n",
      "        [-22, -76, -78,  -7,  -2, -20, -12, -24,  39,   3,  49,  20,  -2,  13,\n",
      "         -20, -28,   8,  39,  25,  58,  38,  -8,  14,  35,  -3, -27,   2,  -4,\n",
      "          -8, -14, -49, -22,  -3, -37, -28, -47, -38,  40, -35,  -7, -11,  75,\n",
      "          19,  36, -13,  -4, -14,  -4],\n",
      "        [-24,   0,   0,  77,  15,  -6,   8,  37,  12,   2,  11, -40,  36,   4,\n",
      "           7, -30,  11,  19, -29, -36, -36,  18, -44, -24,   5, -16,   0,  -6,\n",
      "         -22,   0,  29,   5, -38,   8,  11,  28, -12,   1,  25,  22,  53, -41,\n",
      "          -4,  23,  49,   6,  13, -13],\n",
      "        [-23, -59,  -6,  36, -48, -45,  -8,   4, -11, -25, -25,  16,  16,  -2,\n",
      "          34,  18,  25,  17, -17, -30,  34,  23,  -2,  -5,  -5,  49,  37,  40,\n",
      "         -24, -41,  -2,  -6, -15, -30, -13,   5, -26, -23,  44,  34, -35, -18,\n",
      "          11,  -9, -15,  17,  32,  14],\n",
      "        [ 34,  47,  18, -18, -10,   9,  17, -19,  19, -74,  13,  12, -46,   1,\n",
      "         -20, -32, -22, -20,  -2,  32,  27,  -5,  -4,  11, -22, -23,   8, -27,\n",
      "          24,  -8,  25, -15,  37,  49,  15,   9,  10,   7,  21,   5,  46, -26,\n",
      "         -11,  48, -26, -46, -43, -65],\n",
      "        [ 14,  -4,  11,   6,  24,  11,   4,  31,  -4,  17,  -5,  34,  28, -36,\n",
      "         -20,   6,  30,  15,   0, -12, -25, -14,  24,  16,  35,  33,   0,  -7,\n",
      "         -15,   3,   0,  32,   5, -25, -17,  -2, -44,   0,   2, -14, -32, -17,\n",
      "          17, -17, -43,  -2, -35,  28],\n",
      "        [-41,  15,  46,  10, -27,  -9,  -2, -30, -10,  40,   8, -23,  20,  14,\n",
      "          -3, -44,  29,  39,   6,  13,  -1, -22,   5,  32, -61, -42, -18, -34,\n",
      "           1,  13, -12, -12, -13,   8,  33,  16, -25, -20, -33,  10, -11,  53,\n",
      "         -13, -35,   8,  15, -33, -19]], dtype=torch.int32)\n",
      "tensor([[  1,  12,  27,   1, 255, 253, 251, 246, 253, 192, 230,  27,  30, 220,\n",
      "          24,  43,  12,   6,   2, 248,  34,  34, 243,   5,  28,  11,  12, 252,\n",
      "         249, 251,  13,   9,   8, 243,   6,  14, 245, 240, 226, 220, 216, 248,\n",
      "         231, 215,   9,  34,  16, 247],\n",
      "        [220,   0, 187,   4, 241,  28, 253, 240, 200,  48, 217,   7, 225,  59,\n",
      "         206,  10, 243, 233,  44, 240, 236, 254,  10, 204, 230,  33, 235,  22,\n",
      "          45, 243, 232,   2, 218,   4, 235, 234,  45, 245, 243,  34,  15, 221,\n",
      "         251,  27, 251,  30,  24,  38],\n",
      "        [ 25,  38,  19, 212,  30, 243, 243, 223, 238, 216, 238,   0,   0, 243,\n",
      "          38,  37, 197, 244, 214, 255,  13,  10, 254,  27,  65,  31, 240, 227,\n",
      "          14,   9,   5,  19,  33,  10,  11, 249,  47,  17, 249,   7,  17, 246,\n",
      "           8,   4,  20, 238,  37,  74],\n",
      "        [ 30,  35,  21, 218,   2,   8, 249,  21,  17,  26,   9, 240,  22,   2,\n",
      "          29,  22, 198, 208,   4,  16, 235, 244, 244, 232, 253, 227, 247,  14,\n",
      "           8,   0,  15,  26,  30,   3, 249, 235,   4, 233, 246, 244,  41, 234,\n",
      "         247, 237,  50, 251,  12,   0],\n",
      "        [234, 180, 178, 249, 254, 236, 244, 232,  39,   3,  49,  20, 254,  13,\n",
      "         236, 228,   8,  39,  25,  58,  38, 248,  14,  35, 253, 229,   2, 252,\n",
      "         248, 242, 207, 234, 253, 219, 228, 209, 218,  40, 221, 249, 245,  75,\n",
      "          19,  36, 243, 252, 242, 252],\n",
      "        [232,   0,   0,  77,  15, 250,   8,  37,  12,   2,  11, 216,  36,   4,\n",
      "           7, 226,  11,  19, 227, 220, 220,  18, 212, 232,   5, 240,   0, 250,\n",
      "         234,   0,  29,   5, 218,   8,  11,  28, 244,   1,  25,  22,  53, 215,\n",
      "         252,  23,  49,   6,  13, 243],\n",
      "        [233, 197, 250,  36, 208, 211, 248,   4, 245, 231, 231,  16,  16, 254,\n",
      "          34,  18,  25,  17, 239, 226,  34,  23, 254, 251, 251,  49,  37,  40,\n",
      "         232, 215, 254, 250, 241, 226, 243,   5, 230, 233,  44,  34, 221, 238,\n",
      "          11, 247, 241,  17,  32,  14],\n",
      "        [ 34,  47,  18, 238, 246,   9,  17, 237,  19, 182,  13,  12, 210,   1,\n",
      "         236, 224, 234, 236, 254,  32,  27, 251, 252,  11, 234, 233,   8, 229,\n",
      "          24, 248,  25, 241,  37,  49,  15,   9,  10,   7,  21,   5,  46, 230,\n",
      "         245,  48, 230, 210, 213, 191],\n",
      "        [ 14, 252,  11,   6,  24,  11,   4,  31, 252,  17, 251,  34,  28, 220,\n",
      "         236,   6,  30,  15,   0, 244, 231, 242,  24,  16,  35,  33,   0, 249,\n",
      "         241,   3,   0,  32,   5, 231, 239, 254, 212,   0,   2, 242, 224, 239,\n",
      "          17, 239, 213, 254, 221,  28],\n",
      "        [215,  15,  46,  10, 229, 247, 254, 226, 246,  40,   8, 233,  20,  14,\n",
      "         253, 212,  29,  39,   6,  13, 255, 234,   5,  32, 195, 214, 238, 222,\n",
      "           1,  13, 244, 244, 243,   8,  33,  16, 231, 236, 223,  10, 245,  53,\n",
      "         243, 221,   8,  15, 223, 237]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(model.fc_1.weight))\n",
    "print((model.fc_1.weight * 128).int())\n",
    "\n",
    "int_fc_weight = (model.fc_1.weight * 128).int()\n",
    "\n",
    "# signed int => unsigned int\n",
    "for i in range(10):\n",
    "    for j in range(48):\n",
    "        if int_fc_weight[i][j] < 0 :\n",
    "            int_fc_weight[i][j] += 256\n",
    "        \n",
    "print(int_fc_weight)\n",
    "\n",
    "np.savetxt('fc_weight.txt', int_fc_weight, fmt='%1.2x',delimiter = \" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
